# High Throughput API

DescriÃ§Ã£o: Projeto de API para suporte de alto volume de requisiÃ§Ãµes e mediÃ§Ã£o e comparaÃ§Ã£o de resultados apÃ³s uso e nÃ£o uso de otimizaÃ§Ãµes jÃ¡ conhecidas

API projetada para suportar **alto volume de requisiÃ§Ãµes simultÃ¢neas**, com foco em:
- Baixa latÃªncia
- Alta taxa de throughput
- Cache distribuÃ­do
- ResiliÃªncia
- Observabilidade

Este projeto nÃ£o Ã© um CRUD genÃ©rico. Ele simula um **cenÃ¡rio real de sistemas de grande escala**, como APIs de catÃ¡logo, leitura de dados financeiros, ou endpoints pÃºblicos consumidos por milhÃµes de usuÃ¡rios.

Vou disponibilizar na documentaÃ§Ã£o as mÃ©tricas e comparaÃ§Ãµes do uso de cada otimizaÃ§Ã£o e tambÃ©m quando nÃ£o sÃ£o utilizadas

---

## Objetivo do Projeto

Demonstrar, na prÃ¡tica, como projetar e operar uma API capaz de:
- Atender milhares de requisiÃ§Ãµes por segundo
- Manter latÃªncia previsÃ­vel (p95 / p99)
- Proteger o sistema contra sobrecarga
- Utilizar cache de forma eficiente
- Ser observÃ¡vel em produÃ§Ã£o

---

## DecisÃµes TÃ©cnicas

### Por que Node.js?

Node.js foi escolhido por ser altamente eficiente para sistemas **I/O-bound**, comuns em APIs de leitura massiva.

CaracterÃ­sticas que justificam a escolha:
- Arquitetura non-blocking
- Baixo overhead por requisiÃ§Ã£o
- Excelente escalabilidade horizontal
- Amplamente utilizado em empresas de grande escala

Frameworks como Java e Python sÃ£o excelentes em outros contextos, mas para este tipo especÃ­fico de API, Node.js entrega **melhor custo-benefÃ­cio de performance**.

#### ComparaÃ§Ã£o com JAVA

| CritÃ©rio               | Node.js                   | Java                 |
| ---------------------- | ------------------------- | -------------------- |
| Modelo de concorrÃªncia | Event Loop (non-blocking) | Threads              |
| Overhead por request   | Muito baixo               | Maior                |
| Tempo de bootstrap     | Muito rÃ¡pido              | Mais lento           |
| Consumo de memÃ³ria     | Menor                     | Maior                |
| Ideal para             | APIs I/O-bound            | Processamento pesado |
| LatÃªncia p95/p99       | Excelente                 | Boa                  |

#### ComparaÃ§Ã£o com Python

| CritÃ©rio              | Node.js        | Python         |
| --------------------- | -------------- | -------------- |
| ConcorrÃªncia          | Nativa (async) | Limitada (GIL) |
| Throughput            | Alto           | MÃ©dio          |
| LatÃªncia              | Baixa          | Maior          |
| Uso em APIs de escala | Muito comum    | Raro           |
| Melhor uso            | APIs, gateways | Workers, ML    |


---

### Por que Fastify?

Fastify Ã© um dos frameworks HTTP mais rÃ¡pidos do ecossistema Node.js.

BenefÃ­cios:
- Alta performance
- Baixo consumo de memÃ³ria
- Schema validation nativa
- Suporte a plugins e extensibilidade

---

### Por que Redis?

Redis Ã© utilizado como cache distribuÃ­do para:
- Reduzir carga no banco de dados
- Diminuir latÃªncia
- Proteger o sistema em cenÃ¡rios de pico

---

## Arquitetura (VisÃ£o Geral)

Client
  â†“
Fastify API
  â†“
Cache (Redis)
  â†“
PostgreSQL

Observabilidade:
- OpenTelemetry
- Prometheus
- Grafana

ResiliÃªncia:
- Rate limiting
- Circuit breaker
- Timeout


## Fluxo da RequisiÃ§Ã£o

1. Request chega

2. Rate limiter valida

3. Cache Ã© consultado

4. Se HIT â†’ resposta imediata

5. Se MISS â†’ banco

6. Resposta Ã© cacheada

7. MÃ©tricas sÃ£o coletadas

## Estrutura de pastas

```
high-throughput-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ env.ts                # VariÃ¡veis de ambiente tipadas
â”‚   â”‚   â”œâ”€â”€ redis.ts              # ConexÃ£o Redis
â”‚   â”‚   â”œâ”€â”€ database.ts           # ConexÃ£o PostgreSQL
â”‚   â”‚   â””â”€â”€ observability.ts      # OpenTelemetry setup
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ items/
â”‚   â”‚   â”‚   â”œâ”€â”€ items.controller.ts   # Handlers HTTP
â”‚   â”‚   â”‚   â”œâ”€â”€ items.service.ts      # Regras de leitura
â”‚   â”‚   â”‚   â”œâ”€â”€ items.repository.ts   # Acesso ao banco
â”‚   â”‚   â”‚   â”œâ”€â”€ items.routes.ts       # Rotas Fastify
â”‚   â”‚   â”‚   â”œâ”€â”€ items.schema.ts       # ValidaÃ§Ã£o / OpenAPI
â”‚   â”‚   â”‚   â””â”€â”€ items.types.ts        # Tipos do domÃ­nio
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ health/
â”‚   â”‚       â””â”€â”€ health.routes.ts      # Healthcheck
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â””â”€â”€ redis-cache.ts        # EstratÃ©gia de cache
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ rate-limit/
â”‚   â”‚   â”‚   â””â”€â”€ rate-limit.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ resilience/
â”‚   â”‚   â”‚   â””â”€â”€ circuit-breaker.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â””â”€â”€ metrics.ts            # Prometheus metrics
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â”‚   â””â”€â”€ logger.ts             # Pino logger
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ errors/
â”‚   â”‚       â””â”€â”€ app-error.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ app.ts                        # ConfiguraÃ§Ã£o do Fastify
â”‚   â””â”€â”€ server.ts                     # Bootstrap da aplicaÃ§Ã£o
â”‚
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ items.test.ts
â”‚   â”‚
â”‚   â””â”€â”€ load/
â”‚       â””â”€â”€ k6-script.js              # Teste de carga
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â””â”€â”€ init.sql
â”‚   â”‚
â”‚   â””â”€â”€ redis/
â”‚       â””â”€â”€ redis.conf
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
```

## OtimizaÃ§Ãµes da API
Listarei e explicar resumidamente (por preguiÃ§a) cada otimizaÃ§Ã£o da API que pretendo usar neste projeto

- Caching
- Connection Pool
- Avoid N+1 Problem
- Pagination and Filtering
- JSON Serializers Efficient
- Payload Compression
- Asynchronous Logging
- Load Balancing
- Long-running Requests
- Rate Limiting

### Connection Pool (Pool de ConexÃµes)

O Connection Pool Ã© um conjunto de conexÃµes jÃ¡ abertas e reutilizÃ¡veis, que sÃ£o compartilhadas entre vÃ¡rias requisiÃ§Ãµes

Em vez de:

`Request â†’ abrir conexÃ£o â†’ query â†’ fechar conexÃ£o`

Uso:

`Request â†’ pegar conexÃ£o do pool â†’ query â†’ devolver conexÃ£o ao pool`


```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Requests  â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚     Pool de ConexÃµes     â”‚
  â”‚ â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”     â”‚
  â”‚ â”‚ C1 â”‚ â”‚ C2 â”‚ â”‚ C3 â”‚ ... â”‚  â† conexÃµes abertas
  â”‚ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜     â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚ PostgreSQLâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Quando o app roda o pool de conexÃµes Ã© criado vazio**

## Comandos Ãºteis do projeto

```
npm run dev

npm run build

npm run start

docker-compose up --build

docker-compose down

./scripts/k6-run.sh

./scripts/k6-run.sh test/load/k6-no-pool.js

./scripts/k6-run.sh test/load/k6-cache-vs-db.js



```


## Rotas da aplicaÃ§Ã£o

/items/

/items/items-no-pool

### Rotas de testes

/items/test/items

/items/test/items-no-pool

/items/test/items-cached

## ComparaÃ§Ãµes mÃ©tricas

### COM e SEM Connection Pool

Considerando a query:

`SELECT 1`

Pois o objetivo Ã© apenas testar o diferenÃ§a entre o uso ou nÃ£o de Pool, ou seja, apenas um query simples resolve


Tabela de comparaÃ§Ã£o
| MÃ©trica     | Com Pool    | Sem Pool      |
| ----------- | ----------- | ------------- |
| p95 latency | **5.89 ms** | **162.12 ms** |
| Avg latency | **6.68 ms** | **84.82 ms**  |
| Req/s       | **49.5**    | **45.7**      |

- 50 VUs
- 30s de duraÃ§Ã£o
- Threholds
  - http_req_failed: ['rate<0.01'],
  - http_req_duration: ['p(95)<300'],

A tabela indica que 95% das requisiÃ§Ãµes levaram igual ou menos tempo de execuÃ§Ã£o que 5.89ms com o Pool, enquanto sem Pool 95% levaram igual ou menos tempo que 162.12ms

**O que Ã© uma grande diferenÃ§a em termos de respostas por requisiÃ§Ã£o**

Agora com:

- 100 VUs
- AdicÃ£o de mÃ©trica p99

| MÃ©trica | Com pool | Sem pool    |
| ------- | -------- | ----------- |
| avg     | ~6 ms    | **111 ms**  |
| p95     | ~8 ms    | **206 ms**  |
| p99     | ~112 ms  | **554 ms**  |
| max     | ~155 ms  | **~570 ms** |

Principais mÃ©tricas de interesse:

- http_req_duration: Tempo que cada requisiÃ§Ã£o leva para ser completada. O objetivo aqui Ã© manter esse valor baixo, especialmente no p95 (95% das requisiÃ§Ãµes).
- http_reqs: NÃºmero de requisiÃ§Ãµes por segundo. Indicativo de throughput.
- http_req_failed: Percentual de falhas. Idealmente, 0%.
- iteration_duration: Tempo mÃ©dio de execuÃ§Ã£o de uma iteraÃ§Ã£o. Quanto menor, melhor.


### COM e SEM Cache (Redis)

Vou testar 3 cenÃ¡rios

| CenÃ¡rio | Fonte dos dados        |
| ------- | ---------------------- |
| A       | PostgreSQL (sem cache) |
| B       | Redis (cache HIT)      |
| C       | Cache MISS controlado  |

A comparaÃ§Ã£o serÃ¡ entre endpoint direto no banco com pool e endpoint usando cache redis

| Endpoint                   | DescriÃ§Ã£o           |
| -------------------------- | ------------------- |
| `/items/test/items`        | Banco direto (pool) |
| `/items/test/items-cached` | Cache Redis         |


ğŸ”¹ Teste 1 â€” 50 VUs
| MÃ©trica            | Sem cache (DB) | Com cache (Redis) |
| ------------------ | -------------- | ----------------- |
| RequisiÃ§Ãµes totais | 1500           | 1500              |
| Req/s              | ~49.5          | ~49.5             |
| Avg latency        | 7.97ms         | 7.99ms            |
| p90                | 5.10ms         | 4.17ms            |
| **p95**            | **6.71ms**     | **7.00ms**        |
| **p99**            | **171.56ms**   | **188.03ms**      |
| Max                | 192ms          | 205ms             |
| Erros              | 0%             | 0%                |
| Threshold p95      | âœ…              | âœ…                 |
| Threshold p99      | âœ…              | âœ…                 |

ğŸ”¹ Teste 2 â€” 200 VUs
| MÃ©trica            | Sem cache (DB) | Com cache (Redis) |
| ------------------ | -------------- | ----------------- |
| RequisiÃ§Ãµes totais | 1500           | 1500              |
| Req/s              | ~49.5          | ~49.5             |
| Avg latency        | 7.97ms         | 7.99ms            |
| p90                | 5.10ms         | 4.17ms            |
| **p95**            | **6.71ms**     | **7.00ms**        |
| **p99**            | **171.56ms**   | **188.03ms**      |
| Max                | 192ms          | 205ms             |
| Erros              | 0%             | 0%                |
| Threshold p95      | âœ…              | âœ…                 |
| Threshold p99      | âœ…              | âœ…                 |


ğŸ”¹ Teste 3 â€” 1000 VUs
| MÃ©trica            | Sem cache (DB) | Com cache (Redis) |
| ------------------ | -------------- | ----------------- |
| RequisiÃ§Ãµes totais | ~29.2k         | ~29.7k            |
| Req/s              | ~942           | ~961              |
| Avg latency        | **37.63ms**    | **22.45ms** â¬‡ï¸    |
| p90                | 7.36ms         | 5.23ms            |
| **p95**            | **12.1ms** âŒ   | **8.41ms** âœ…      |
| **p99**            | **1.5s** âŒ     | **617ms** âŒ       |
| Max                | 2.32s          | 1.41s             |
| Erros              | 0%             | 0%                |
| Threshold p95      | âŒ              | âœ…                 |
| Threshold p99      | âŒ              | âŒ                 |


ğŸ”¹ ComparaÃ§Ã£o Geral

| VUs  | Cache | Avg         | p95        | p99      | Max   | Req/s | Threshold |
| ---- | ----- | ----------- | ---------- | -------- | ----- | ----- | --------- |
| 50   | âŒ     | 7.97ms      | 6.71ms     | 171ms    | 192ms | ~49   | âœ…         |
| 50   | âœ…     | 7.99ms      | 7.00ms     | 188ms    | 205ms | ~49   | âœ…         |
| 200  | âŒ     | 9.23ms      | 7.66ms     | 216ms    | 298ms | ~197  | âœ…         |
| 200  | âœ…     | 10.43ms     | **4.75ms** | 289ms    | 349ms | ~197  | âœ…         |
| 1000 | âŒ     | **37.63ms** | **12.1ms** | **1.5s** | 2.32s | ~942  | âŒ         |
| 1000 | âœ…     | **22.45ms** | **8.41ms** | 617ms    | 1.41s | ~961  | âŒ         |

#### Cache tambÃ©m pode virar gargalo

Redis:
- single-thread
- responde rÃ¡pido, mas fila sob carga extrema
- precisa:
  - sharding
  - replicas
  - pipeline

ou local cache (LRU in-memory)


### Rate Limiting â€” Testes de Carga

CÃ³digo de teste no terminal
```
for i in {1..120}; do
  curl -s -o /dev/null -w "%{http_code}\n" http://127.0.0.1:3000/items
done
```

#### Testes

| Teste | Objetivo |
|----|--------|
| burst | Validar bloqueio sob explosÃ£o |
| cooldown | Verificar recuperaÃ§Ã£o apÃ³s janela |
| isolation | Garantir isolamento entre clientes |
| performance-impact | Medir impacto em latÃªncia |

#### ExecuÃ§Ã£o

```bash
./scripts/k6-run.sh ./test/load/rate-limiting/burst.test.js
./scripts/k6-run.sh ./test/load/rate-limiting/cooldown.test.js
./scripts/k6-run.sh ./test/load/rate-limiting/isolation.test.js
./scripts/k6-run.sh ./test/load/rate-limiting/performance-impact.test.js
```

ApÃ³s implementado testado o burst usando k6 para validar o comportamento do rate limiting sob rajada rÃ¡pida de requisiÃ§Ãµes de um Ãºnico cliente. O sistema respondeu corretamente com HTTP 200 e 429, sem erros 5xx, mantendo baixa latÃªncia e estabilidade.

Teste de Burst

| MÃ©trica          | Resultado       |
| ---------------- | --------------- |
| VUs              | 1               |
| IteraÃ§Ãµes        | 50              |
| DuraÃ§Ã£o total    | ~0.1s           |
| Status esperados | 200             |
| p95 latÃªncia     | 2.55ms          |
| Erros            | 0%              |
| Throughput       | ~416 req/s      |
| Comportamento    | âœ… Aceitou burst |

- O rate limiter nÃ£o bloqueia rajadas curtas
- LatÃªncia mÃ­nima
- Sem impacto perceptÃ­vel

Teste de Cooldown

| MÃ©trica                  | Resultado |
| ------------------------ | --------- |
| VUs                      | 1         |
| IteraÃ§Ãµes                | 15        |
| Intervalo entre requests | ~5s       |
| Status esperados         | 200       |
| p95 latÃªncia             | 3.75ms    |
| Erros                    | 0%        |
| Tempo de recuperaÃ§Ã£o     | ~1 janela |


- O rate limiter libera corretamente apÃ³s o tempo
- NÃ£o ocorre bloqueio permanente
- Estado limpo entre janelas

Teste de Isolamento entre usuÃ¡rios

| MÃ©trica               | Resultado |
| --------------------- | --------- |
| VUs                   | 20        |
| IteraÃ§Ãµes             | 100       |
| p95 latÃªncia          | 102.89ms  |
| Erros                 | 0%        |
| Status vÃ¡lidos        | 200 / 429 |
| InterferÃªncia cruzada | âŒ Nenhuma |

- Rate limit aplicado por chave (IP/cliente)

Teste de Performance

| MÃ©trica                      | Resultado    |
| ---------------------------- | ------------ |
| VUs                          | 100          |
| DuraÃ§Ã£o                      | 30s          |
| Total de requests            | 132.753      |
| Throughput                   | ~4.422 req/s |
| p95 latÃªncia                 | 33.33ms      |
| p99 latÃªncia                 | ~176ms       |
| RequisiÃ§Ãµes bloqueadas (429) | ~99.9%       |
| Colapso do sistema           | âŒ NÃ£o        |

- O rate limiter rejeita rÃ¡pido
- Sistema permanece estÃ¡vel
- LatÃªncia nÃ£o explode
- Banco/cache protegidos

Resumo

| CenÃ¡rio           | Protege o sistema | Impacto de latÃªncia | Comportamento esperado |
| ----------------- | ----------------- | ------------------- | ---------------------- |
| Burst curto       | âœ…                 | Nenhum              | Aceita                 |
| Cooldown          | âœ…                 | Nenhum              | Recupera               |
| Isolamento        | âœ…                 | Baixo               | UsuÃ¡rios isolados      |
| SaturaÃ§Ã£o extrema | âœ…                 | Controlado          | Bloqueia massivamente  |

